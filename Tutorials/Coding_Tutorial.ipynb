{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Best Practices Tutorial\n",
    "This tutorial will use `Python` to illustrate coding best practices.  It will review the  basics of `Python`, cover useful `Python` libraries for performing sofisticated calculations, and sample topics including encapsulation, code modularity and code reusability.  The concepts will be introduced by developing a small code base to do linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "---\n",
    "#### Goal:  Write a `Python` module that provides support for some linear regression techniques.\n",
    "---\n",
    "## Part 1:  Getting Started\n",
    "* Motivating Example\n",
    "* Basic `Python`\n",
    "* Write a `Python` script\n",
    "---\n",
    "## Part 2:  Towards Modularity\n",
    "* Functions\n",
    "* Nested functions and encapsulation\n",
    "---\n",
    "## Part 3:  Tying It All Together\n",
    "* Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "---\n",
    "### The Model\n",
    "Linear regression represents a simple model-fitting technique.  We are given $n$ observations $\\mathbf{y} \\in \\mathbb{R}^{n}$ and wish to fit these observations to the linear model \n",
    "$$\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$$\n",
    "where $\\mathbf{X} \\in \\mathbb{R}^{n\\times p}$ is a matrix of $p$ regressors for each observation and $\\boldsymbol{\\beta} \\in \\mathbb{R}^{p}$ is a vector of $p$ *unknown* parameters.  Note that $\\boldsymbol{\\epsilon}$ is a vector of random variables representing the error between the actual observations and the predictions.\n",
    "### Ordinary Least Squares Solution\n",
    "We want to find the parameters $\\boldsymbol{\\beta}$ that give us the best fit to our data.  One famous approach is to try to find the $\\boldsymbol{\\beta}$ which minimizes the $L_{2}$ error between the prediction and observations,\n",
    "$$\\underset{\\boldsymbol{\\beta}\\in\\mathbb{R}^{p}}{\\operatorname{argmin}} \\|\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}\\|_{_{\\large 2}}.$$\n",
    "After solving this problem, we find that the parameters that lead to the best solution (in the OLS) sense are given by \n",
    "$$\\widehat{\\boldsymbol{\\beta}} = \\left(\\mathbf{X}^{T}\\mathbf{X}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{y}.$$\n",
    "Given a data point $\\left\\{y_{i}, x_{i}\\right\\}_{i=1}^{n}$, we can find the best fit parameters $\\boldsymbol{\\beta}$ with the formula above.  Then, if we're bold, we can endeavor to make predictions with our linear model.\n",
    "### How Good is the Solution?\n",
    "One way to measure how good of a fit the linear model is to the data is to use the *coefficient of determination*, $R^{2}$.  It is defined as \n",
    "$$R^{2} = 1 - \\frac{\\displaystyle\\sum_{i}{\\left(y_{i} - \\widehat{y}_{i}\\right)^{2}}}{\\displaystyle\\sum_{i}{\\left(y_{i} - \\overline{y}\\right)^{2}}}.$$\n",
    "If $R^{2} = 1$ then the regression line fits the data perfectly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## The Basics in `Python`\n",
    "Our ultimate goal is to write a resuable, well-documented code that allows us to do the following:\n",
    "1. Compute the best-fit parameters given some data\n",
    "2. Predict new observations with our linear model\n",
    "3. Compute the $R^{2}$ value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 5.0\n",
      "y = 6.0\n",
      "x < y b/c x = 5.0 and y = 6.0\n",
      "x > x^2. Exiting loop now.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# This is a comment\n",
    "# Let's declare some variables\n",
    "x = 5.0\n",
    "y = 6.0\n",
    "# We can print things out too\n",
    "print(\"x = {0}\".format(x))\n",
    "print(\"y = {0}\".format(y))\n",
    "\n",
    "# Here are the basic operations on numbers\n",
    "z1 = x + y\n",
    "z2 = x - y\n",
    "z3 = x * y\n",
    "z4 = x / y\n",
    "z5 = x**2\n",
    "\n",
    "# Here are the basic logical constructs\n",
    "\n",
    "# if statements\n",
    "if (x < y):\n",
    "    print(\"x < y b/c x = {0} and y = {1}\".format(x, y))\n",
    "elif (x > y):\n",
    "    print(\"x > y b/c x = {0} and y = {1}\".format(x, y))\n",
    "elif (x == y):\n",
    "    print(\"x = y b/c x = {0} and y = {1}\".format(x, y))\n",
    "else:\n",
    "    print(\"Other comparisons don't really make sense for real numbers.\")\n",
    "\n",
    "# while loops\n",
    "\n",
    "# Preferred option\n",
    "while True:\n",
    "    if (x >= z5):\n",
    "        print(\"x > x^2. Exiting loop now.\")\n",
    "        break\n",
    "    x += 1\n",
    "\n",
    "# Alternate option\n",
    "while y < z5:\n",
    "    y += 2\n",
    "\n",
    "# for loops\n",
    "for idx in range(5):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few notes on the `for` statement\n",
    "1. We introduced the `range` iterator\n",
    "```python\n",
    "# Practice with range()\n",
    "print(range(10)) # The numbers from 0 to 9\n",
    "print(range(1,10)) # The numbers from 1 to 9\n",
    "print(range(1,10,2)) # The numbers from 0 to 9 in steps of 2\n",
    "```\n",
    "2. `for` *iterates* over values generated by the iterator\n",
    "3. `Python` starts counting from zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you'd really like to do more involved calculations.  We're after an expression (for the parameters $\\boldsymbol{\\beta}$) which involves matrix and vector manipulations.\n",
    "\n",
    "`Python` better have a way of manipulating such objects and it does.  In fact, `Python` has a variety of data structures, most of which we will skip over today.\n",
    "\n",
    "Our focus will be on the `NumPy` and `SciPy` libraries.  These libraries are sophisticated packages which can be imported into your `Python` codes.  `SciPy` is built on top of `NumPy` and offers algorithms for a variety of domains including statistical analysis.  `NumPy` contains algorithms that operate on matrix and array data types (e.g. matrix multiplication and other linear algebra algorithms).\n",
    "\n",
    "For more information, consult the [`NumPy` Documentation](http://www.numpy.org/) and the [`SciPy` Documentation](https://www.scipy.org/).\n",
    "\n",
    "In order to use `NumPy` and `SciPy` we must import them into our script.  But we haven't written any scripts yet!  Not to worry.  We can do that now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A `Python` Script\n",
    "Any meaningful code is contained in files with the proper extension.  `Python` scripts have a `.py` extension.\n",
    "\n",
    "#### Creating a new `.py` file\n",
    "* If you are working with an IDE (like Spyder), then simply create a new file and save it as `meaningful_name.py`.  It's best if you don't have any spaces in your file names.\n",
    "* If you are creating scripts from a terminal, just open your favorite text editor and save the file as `meaningful_name.py`. \n",
    "* Finally, if you are working in the `Jupyter` notebook, then you can save a file directly from a cell simply by using the `%%writefile meaningful_name.py`.\n",
    "\n",
    "#### Running your script\n",
    "* If you are working with an IDE, you can usually run your current script.  Each IDE is different.  Spyder has a \"play\" button.\n",
    "* To run a `.py` file from the terminal, simply type `python meaningful_name.py` and `Python` will run it.\n",
    "* To run a script from a `Jupyter` notebook cell, simply run the cell.  You can load a file into a `Jupyter` notebook by writing `%load meaningful_name.py` into a `Jupyter` notebook cell.  You can run a loaded file from a `Jupyter` notebook cell by writing `%run meaningful_name.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing first_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile first_script.py\n",
    "# A First Python Script\n",
    "x = 2.0\n",
    "\n",
    "# Calculate powers of 2\n",
    "for i in range(11):\n",
    "    print(x**i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Modules\n",
    "We can't wait any longer.  We need to implement the formula for the parameters.  Of course, that formula involves a bunch of matrix-matrix and matrix-vector products as well as matrix transposes and inverses!\n",
    "\n",
    "Not to worry.  We'll use `NumPy` to handle it all for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[-1  3  2]\n",
      " [ 2  1  7]\n",
      " [ 3  6 -5]]\n",
      "\n",
      "v = \n",
      " [ 1 -1  3]\n",
      "\n",
      "C = \n",
      " [[-15  -7]\n",
      " [ 25  -8]\n",
      " [-56  19]]\n",
      "\n",
      "A^T = \n",
      " [[-1  2  3]\n",
      " [ 3  1  6]\n",
      " [ 2  7 -5]]\n",
      "\n",
      "detA = 158.0\n",
      "\n",
      "A has size: (3, 3)\n",
      "with 3 rows and 3 columns.\n"
     ]
    }
   ],
   "source": [
    "# NumPy Example\n",
    "import numpy as np # import NumPy and give it the alias np\n",
    "\n",
    "# Create some matrices and vectors\n",
    "A = np.array([ [-1, 3, 2], [2, 1, 7], [3, 6, -5] ])\n",
    "B = np.array([ [2, 3], [-7, 0], [4, -2] ])\n",
    "v = np.array([1, -1, 3])\n",
    "\n",
    "# Matrix operations\n",
    "M = A + A # Matrix addition\n",
    "C = np.dot(A, B) # Matrix multiplication\n",
    "u = np.dot(A, v) # Matrix vector product\n",
    "\n",
    "AT = A.T # Transpose matrix\n",
    "Ainv = np.linalg.inv(A) # Inverse matrix\n",
    "detA = np.linalg.det(A) # Determinant\n",
    "\n",
    "print(\"A =\\n {}\\n\".format(A))\n",
    "print(\"v = \\n {}\\n\".format(v))\n",
    "\n",
    "print(\"C = \\n {}\\n\".format(C))\n",
    "print(\"A^T = \\n {}\\n\".format(AT))\n",
    "print(\"detA = {0:5.1f}\\n\".format(detA))\n",
    "\n",
    "print(\"A has size: {}\".format(A.shape))\n",
    "print(\"with {0} rows and {1} columns.\".format(A.shape[0], A.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a `Python` Script\n",
    "Let's put the calculation of $\\boldsymbol{\\beta}$ into a script.  We need to generate some data first.  We'll use some built-in datasets from the [`scikit-learn`](http://scikit-learn.org/stable/) package, which, among other things, provides data analysis tools.\n",
    "\n",
    "**Note:** Don't worry if you don't understand some of the details in the script yet.  We will cover them shortly.  For now, the main thing you need to worry about is that you understand how to structure the script and how to use `NumPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing regression_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile regression_script.py\n",
    "\"\"\"A Script to Compute OLS best-fit parameters\n",
    "This script imports data from sklearn and calculates \n",
    "the best fit parameters for that data.\n",
    "\n",
    "In the future, this script will also compute the R^2 \n",
    "score and make predictions from the linear model.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn import datasets # import the datasets module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = datasets.load_boston() # load the Boston dataset on Boston house-prices\n",
    "\n",
    "# Split the dataset in the a training portion (used to get the parameters) and a \n",
    "# test portion (used to make predictions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], \n",
    "                                                    dataset['target'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "\n",
    "column_of_ones = np.ones([X_train.shape[0], 1]) # create a vector of ones\n",
    "\n",
    "# append the column of ones to the last column of X_train\n",
    "X = np.append(column_of_ones, X_train, axis=1)\n",
    "\n",
    "# Now calculate the betas!\n",
    "Xpinv = np.linalg.pinv(X) # Compute (X^T * X)^(-1) * X^T\n",
    "beta = np.dot(Xpinv, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll add the prediction and $R^2$ calculations to our script now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting regression_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile regression_script.py\n",
    "\"\"\"A Script to Compute OLS best-fit parameters\n",
    "This script imports data from sklearn and calculates \n",
    "the best fit parameters for that data.\n",
    "\n",
    "In the future, this script will also compute the R^2 \n",
    "score and make predictions from the linear model.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn import datasets # import the datasets module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = datasets.load_boston() # load the Boston dataset on Boston house-prices\n",
    "\n",
    "# Split the dataset in the a training portion (used to get the parameters) and a \n",
    "# test portion (used to make predictions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], \n",
    "                                                    dataset['target'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "\n",
    "column_of_ones = np.ones([X_train.shape[0], 1]) # create a vector of ones\n",
    "# append the column of ones to the last column of X_train\n",
    "X = np.append(column_of_ones, X_train, axis=1)\n",
    "\n",
    "# Now calculate the betas!\n",
    "Xpinv = np.linalg.pinv(X) # Compute (X^T * X)^(-1) * X^T\n",
    "beta = np.dot(Xpinv, y_train)\n",
    "\n",
    "# Let's make a prediction with our model\n",
    "y_pred = np.dot(X_test, beta[1:]) + beta[0]\n",
    "\n",
    "# Now let's assess how good that prediction is using the R^2 value\n",
    "y_bar = np.mean(y_test) # Calculate the mean of the test data\n",
    "SST = np.sum((y_test - y_bar)**2.0) # Calculate the total sum of squares\n",
    "SSR = np.sum((y_pred - y_test)**2.0) # Calculate the sum of the square residuals\n",
    "R2 = 1.0 - SSR / SST\n",
    "\n",
    "print(\"R^2 = {0:17.16f}\".format(R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a script from our notebook with the `%run` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 = 0.6839557243179275\n"
     ]
    }
   ],
   "source": [
    "%run regression_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "What have we accomplished so far?\n",
    "* Learned some basics of `Python`\n",
    "* Learned about some key `Python` libraries\n",
    "* Learned how to write a `Python` script\n",
    "\n",
    "This is all well and good, but our script is not very useful.  Here's why:\n",
    "* It would be a nightmare to reuse.  What if we change variable names or want to use a different type of regression?\n",
    "* Everything is exposed to the user.  We should really hide some of the implementation details.  The art is to expose just the write amount of the guts to the user.\n",
    "* Our script has almost no modularity or portability.\n",
    "\n",
    "In the next part, we will talk about writing functions in `Python`.  This will lead us to enpasulation and modularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "The first thing we should do to fix our script up is to write some functions.\n",
    "\n",
    "Functions allow us to inject an element of reusability into our script.  Here are the functions we want:\n",
    "1. A function to compute the $\\boldsymbol{\\beta}$\n",
    "2. A function to predict the new values of $\\mathbf{y}$ once we have $\\boldsymbol{\\beta}$\n",
    "3. A function to compute $R^{2}$ based on the predicted values\n",
    "\n",
    "I'll write the first function.  To begin, I'll just write the function directly in the `Jupyter` notebook.  Ultimately, you will put all the functions in your regression script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all the important modules that we used in our script, \n",
    "# load the dataset, and split the dataset into training and testing \n",
    "# portions.\n",
    "import numpy as np\n",
    "from sklearn import datasets # import the datasets module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = datasets.load_boston() # load the Boston dataset on Boston house-prices\n",
    "\n",
    "# Split the dataset in the a training portion (used to get the parameters) and a \n",
    "# test portion (used to make predictions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], \n",
    "                                                    dataset['target'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write functions with the `def` statement in `Python`.  The basic structure is `def func_name(arg_list):`.  **You must have the colon!**  If you don't include it, you'll get errors.\n",
    "\n",
    "After the declaration statement, the first line of the function must be indented four spaces.  `Python` is indentation-sensitive.  If you don't indent things properly, `Python` won't know what's in the function body.\n",
    "\n",
    "Okay, enough of that.  Let's write the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now write the function.\n",
    "def param_coeffs(training_data, X):\n",
    "    column_of_ones = np.ones([X.shape[0], 1]) # create a vector of ones\n",
    "    # append the column of ones to the last column of X_train\n",
    "    X = np.append(column_of_ones, X, axis=1)\n",
    "\n",
    "    # Now calculate the betas!\n",
    "    Xpinv = np.linalg.pinv(X) # Compute (X^T * X)^(-1) * X^T\n",
    "    beta = np.dot(Xpinv, training_data)\n",
    "    \n",
    "    # Finally, return the parameter coefficients\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function is pretty straightfoward.  We simply call it and pass in the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.98833456e+01  -1.27824912e-01   2.95208977e-02   4.92643105e-02\n",
      "   2.77594439e+00  -1.62801962e+01   4.36089596e+00  -9.19111559e-03\n",
      "  -1.40172019e+00   2.57458956e-01  -9.94705777e-03  -9.24266403e-01\n",
      "   1.33164215e-02  -5.18565634e-01]\n"
     ]
    }
   ],
   "source": [
    "beta = param_coeffs(y_train, X_train)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn!\n",
    "Write a function to compute `y_pred` and another function to compute $R^{2}$.\n",
    "\n",
    "The user should be able to call them like so:\n",
    "1. `y_pred = predict(X_test, beta)`\n",
    "2. `R2 = score(y_test, y_pred)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the Functions Together\n",
    "Now you've written some nice functions.  Your crazy script is becoming more modular by the minute!  You should now put your functions into a script.  The idea here is that your script starts with a bunch of function definitions and at the bottom of the script you have your main statements that use the functions to accomplish the task you want to accomplish.  Watch this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing regression_script_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile regression_script_functions.py\n",
    "\"\"\"A Script to Compute OLS best-fit parameters\n",
    "This script imports data from sklearn and calculates \n",
    "the best fit parameters for that data.\n",
    "\"\"\"\n",
    "def param_coeffs(training_data, X):\n",
    "    \"\"\"Compute the best fit parameters.\n",
    "    INPUTS:\n",
    "        training_data: Data from the training set\n",
    "        X: Attributes\n",
    "    OUTPUT: \n",
    "        beta: Best fit parameters computed from \n",
    "              an OLS calculation.\n",
    "    \"\"\"\n",
    "    # Create a vector of ones and append \n",
    "    # to the last column of X.  Used to \n",
    "    # get the intercept intercepts.\n",
    "    column_of_ones = np.ones([X.shape[0], 1])\n",
    "    X = np.append(column_of_ones, X, axis=1)\n",
    "\n",
    "    # Now calculate the betas!\n",
    "    Xpinv = np.linalg.pinv(X) # Compute (X^T * X)^(-1) * X^T\n",
    "    beta = np.dot(Xpinv, training_data)\n",
    "    \n",
    "    # Finally, return the parameter coefficients\n",
    "    return beta\n",
    "\n",
    "def predict(X, beta):\n",
    "    \"\"\"Predict new outputs from linear fit\n",
    "    INPUTS:\n",
    "        X: Test data\n",
    "        beta:  Best fit parameters\n",
    "    OUTPUTS:\n",
    "        y_pred:  Predicted values\n",
    "    \"\"\"\n",
    "    y_pred = np.dot(X, beta[1:]) + beta[0]\n",
    "    return y_pred\n",
    "\n",
    "def score(test_data, prediction):\n",
    "    \"\"\"Calcuate coefficient of determination\n",
    "    INPUTS:\n",
    "        test_data: Test data from dataset\n",
    "        prediction:  Predicted values (from linear regression)\n",
    "    OUTPUTS:\n",
    "        R2: Coefficient of determination. Here, just the R^2 value.\n",
    "    \"\"\"\n",
    "    # Compute the R^2 value\n",
    "    y_bar = np.mean(test_data) # Calculate the mean of the test data\n",
    "    SST = np.sum((test_data - y_bar)**2.0) # Calculate the total sum of squares\n",
    "    SSR = np.sum((prediction - test_data)**2.0) # Calculate the sum of the square residuals\n",
    "    return 1.0 - SSR / SST # Return R^2 value\n",
    "\n",
    "# Now we're prepared to use our functions.  Since we have some \n",
    "# modularity to our code now, we can do things on more than one \n",
    "# set of data without a big overhaul of our script!\n",
    "import numpy as np\n",
    "from sklearn import datasets # import the datasets module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Do things with the Boston dataset\n",
    "dataset = datasets.load_boston() # load the Boston dataset on Boston house-prices\n",
    "# Split the dataset in the a training portion (used to get the parameters) and a \n",
    "# test portion (used to make predictions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], \n",
    "                                                    dataset['target'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "\n",
    "beta = param_coeffs(y_train, X_train)\n",
    "y_pred = predict(X_test, beta)\n",
    "R2 = score(y_test, y_pred)\n",
    "print(\"R^2 for the Boston dataset is {0:4.3f}.\".format(R2))\n",
    "\n",
    "### Do things with the breast_cancer dataset\n",
    "dataset = datasets.load_breast_cancer() # load the Boston dataset on Boston house-prices\n",
    "# Split the dataset in the a training portion (used to get the parameters) and a \n",
    "# test portion (used to make predictions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], \n",
    "                                                    dataset['target'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "beta = param_coeffs(y_train, X_train)\n",
    "y_pred = predict(X_test, beta)\n",
    "R2 = score(y_test, y_pred)\n",
    "print(\"R^2 for the breast_cancer dataset is {0:4.3f}.\".format(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for the Boston dataset is 0.684.\n",
      "R^2 for the breast_cancer dataset is 0.732.\n"
     ]
    }
   ],
   "source": [
    "%run regression_script_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was fantastic! We got to use multiple datasets and only had to change the input data.  The user was mostly protected from the implementation details.  You just need to tell them how to use each function and they're good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude:  Encapsulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just mentioned hiding details from the user.  This leads us to the idea of **encapsulation**.  What does it mean to hide details?  Essentially, it means that we want to prohibit the user from having direct access to certain objects (e.g. functions).  We just want them to use the objects!  This also has the nice side effect of providing a cleaner and more general coding interface.\n",
    "\n",
    "Let's illustrate this idea with a simple example.  Then we'll implement some of our regression stuff with encapsulation in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  Complex Numbers\n",
    "Recall that a complex number is represented by a real part, $a$, and an imaginary part, $b$ as \n",
    "$$z = a + ib$$ where $i = \\sqrt{-1}$.\n",
    "\n",
    "Let's begin by writing a function that returns a complex number given its two components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 2i\n"
     ]
    }
   ],
   "source": [
    "def complex(a,b):\n",
    "    return \"{0} + {1}i\".format(a,b)\n",
    "\n",
    "z = complex(1,2)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's nothing special so far.  The interesting stuff starts happening if we try to query the real or imaginary components of this number.  There is no way to do this at the moment.  We can accomplish this by using nested functions.  In `Python`, a function can be returned from another function!\n",
    "\n",
    "```python\n",
    "# Define outer function\n",
    "def outer_func(some_args):\n",
    "    # Define inner function\n",
    "    def inner_func(inner_args):\n",
    "        # Compute some things and \n",
    "        # return stuff\n",
    "        return stuff\n",
    "     # Return the inner function\n",
    "    return inner_func\n",
    "\n",
    "# Now we can create instances of our outer function\n",
    "name1 = outer_func(args) # first instance\n",
    "name2 = outer_func(args2) # second instance\n",
    "\n",
    "# And now eac instance can access the calculations \n",
    "# done in the inner function independently!\n",
    "thing1 = name1(in_args)\n",
    "thing2 = name2(in_args2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example with our complex number case.  Our outer function will simply create a complex \n",
    "number instance.  The inner function will accept queries to do some operations on the complex number or print out information pertaining to the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def complex(a,b):\n",
    "    def complex_queries(query):\n",
    "        if query == \"real\":\n",
    "            return a\n",
    "        elif query == \"imaginary\":\n",
    "            return b\n",
    "        elif query == \"magnitude\":\n",
    "            return np.sqrt(a**2.0 + b**2.0)\n",
    "        elif query == \"cartesian\":\n",
    "            return \"{0} + {1}i\".format(a,b)\n",
    "        elif query == \"polar\":\n",
    "            r = np.sqrt(a**2.0 + b**2.0)\n",
    "            theta = np.arctan(b / a)\n",
    "            return \"{0}exp(i {1})\".format(r,theta)\n",
    "        else:\n",
    "            print(\"Query not recognized.\")\n",
    "            return 0\n",
    "    return complex_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our complex number is 3 + 4i.\n",
      "It can be expression in polar form as z = 5.0exp(i 0.9272952180016122).\n",
      "It has magnitude |z| = 5.0.\n",
      "The real part is Re(z) = 3.\n",
      "The real part is Im(z) = 4.\n"
     ]
    }
   ],
   "source": [
    "z = complex(3,4)\n",
    "real_part = z(\"real\")\n",
    "imag_part = z(\"imaginary\")\n",
    "magnitude = z(\"magnitude\")\n",
    "cartesian = z(\"cartesian\")\n",
    "polar_form = z(\"polar\")\n",
    "\n",
    "print(\"Our complex number is {}.\".format(cartesian))\n",
    "print(\"It can be expression in polar form as z = {}.\".format(polar_form))\n",
    "print(\"It has magnitude |z| = {}.\".format(magnitude))\n",
    "print(\"The real part is Re(z) = {}.\".format(real_part))\n",
    "print(\"The real part is Im(z) = {}.\".format(imag_part))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all looks really nice.  Now the user can spawn as many instances of the function `complex` as they want and they'll automatically have access to the `complex_queries` function without even knowing it.\n",
    "\n",
    "Moreover, the `complex_queries` function has knowledge about `a` and `b` from the wrapping function.  However, `complex_queries` cannot change the values of `a` and `b` without some special processing that we won't talk about here (see documentation on the `nonlocal` keyword).\n",
    "\n",
    "One major issue is that there is no way for the user to change the complex number once they have created it.  There are ways around this using the nested function structure, but they're a little bit clunky.  People usually consider more *object oriented* approaches like classes and modules at this point.  We'll consider those a little bit later.\n",
    "\n",
    "For now, let's do an exercise where we use this nested function structure for our regression work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  Nested Functions for Linear Regression\n",
    "Redo the regression example again. This time, use a nested function struture in the form:\n",
    "```python\n",
    "# Here's the nested functions\n",
    "def OLS_regression():\n",
    "    def param_coeffs(...):\n",
    "        ...\n",
    "        return beta\n",
    "    def predict(...):\n",
    "        ...\n",
    "        return y_pred\n",
    "    def score(...):\n",
    "        ...\n",
    "        return R2\n",
    "    return param_coeffs, predict, score\n",
    "\n",
    "# Here's how we make them available\n",
    "p_coeffs, pred, score = OLS_regression()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the \"answer\".  Maybe you did yours slightly differently.  Either way, I hope you wrote it up on your own without looking at my \"solution\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OLS_regression():\n",
    "    def param_coeffs(training_data, X):\n",
    "        \"\"\"Compute the best fit parameters.\n",
    "        INPUTS:\n",
    "            training_data: Data from the training set\n",
    "            X: Attributes\n",
    "        OUTPUT: \n",
    "            beta: Best fit parameters computed from \n",
    "                  an OLS calculation.\n",
    "        \"\"\"\n",
    "        # Create a vector of ones and append \n",
    "        # to the last column of X.  Used to \n",
    "        # get the intercept intercepts.\n",
    "        column_of_ones = np.ones([X.shape[0], 1])\n",
    "        X = np.append(column_of_ones, X, axis=1)\n",
    "\n",
    "        # Now calculate the betas!\n",
    "        Xpinv = np.linalg.pinv(X) # Compute (X^T * X)^(-1) * X^T\n",
    "        beta = np.dot(Xpinv, training_data)\n",
    "\n",
    "        # Finally, return the parameter coefficients\n",
    "        return beta\n",
    "\n",
    "    def predict(X, beta):\n",
    "        \"\"\"Predict new outputs from linear fit\n",
    "        INPUTS:\n",
    "            X: Test data\n",
    "            beta:  Best fit parameters\n",
    "        OUTPUTS:\n",
    "            y_pred:  Predicted values\n",
    "        \"\"\"\n",
    "        y_pred = np.dot(X, beta[1:]) + beta[0]\n",
    "        return y_pred\n",
    "\n",
    "    def score(test_data, prediction):\n",
    "        \"\"\"Calcuate coefficient of determination\n",
    "        INPUTS:\n",
    "            test_data: Test data from dataset\n",
    "            prediction:  Predicted values (from linear regression)\n",
    "        OUTPUTS:\n",
    "            R2: Coefficient of determination. Here, just the R^2 value.\n",
    "        \"\"\"\n",
    "        # Compute the R^2 value\n",
    "        y_bar = np.mean(test_data) # Calculate the mean of the test data\n",
    "        SST = np.sum((test_data - y_bar)**2.0) # Calculate the total sum of squares\n",
    "        SSR = np.sum((prediction - test_data)**2.0) # Calculate the sum of the square residuals\n",
    "        return 1.0 - SSR / SST # Return R^2 value\n",
    "    return param_coeffs, predict, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our nested functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.683955724318\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets # import the datasets module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Do things with the Boston dataset\n",
    "dataset = datasets.load_boston() # load the Boston dataset on Boston house-prices\n",
    "# Split the dataset in the a training portion (used to get the parameters) and a \n",
    "# test portion (used to make predictions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], \n",
    "                                                    dataset['target'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "p, pred, score = OLS_regression()\n",
    "beta = p(y_train, X_train)\n",
    "y_pred = pred(X_test, beta)\n",
    "R2 = score(y_test, y_pred)\n",
    "print(R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Notice that I did not pass any arguments into the `OLS_regression()` method.  This is a design decision.  By doing it this way, I allow the user to create a regression instance which makes available general methods for computing parameter coefficients, making predictions, and computing a best-fit score.  The user can then use those same routines on any dataset they wish to.\n",
    "\n",
    "An alternative design would have been to pass the dataset into the `OLS_regression` method (i.e. `OLS_regression(dataset)`) and to unpack all the data before defining any of the regression functions.  This would have required us to modify our nested functions slightly because the nested functions are now completely aware of all the names defined in the wrapper function.  The nested functions do not have the authority to change those names; they can only make use of them (encapsulation!).  With this design, the nested functions are only good for the particular dataset that was originally passed in when we instantiated the OLS regression.  Maybe some of you took this approach.  If not, you should think about how to implement it sometime and deside what works best for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "Time to regroup.  What have we learned so far?\n",
    "* You can write basic `Python`.\n",
    "* You can write and run `Python` scripts.\n",
    "* You learned how to write functions and why they're important.\n",
    "* We discussed modularity via functions.\n",
    "* The concept of encapsulation was introduced via nested functions.\n",
    "* We started to see why modularity and encapsulation are beneficial for writing a code.\n",
    "\n",
    "These principles are not only useful for your clients.  Many researches and PhD students are their own client.  You want to write a code that is easy to maintain and use.  Do yourself a favor and write functions to help break down the work into pieces.\n",
    "\n",
    "We're on the cusp of object-oriented programming.  We won't get quite that far today.  Right now we'll introduce modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules\n",
    "So far, all of the functions that you've written live in the same script as your main program.  Even though we have some modularity through functions, we still have a lot of extra junk in our script that obscures its functionality.\n",
    "\n",
    "The right thing to do is to lift the functions out of our main script and put them in their own module.  Then the user can write their own main script, import the module they need, and have access to all of the functions through that module.  We've been toying with those ideas a little bit when we imported `numpy` and `sklearn`.  Now you get to write your own module!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty straightforward to write a module in `Python`.  You just put all of your functions into a `.py` file.  In the script that is destined to use those functions, you simply import the module.  After importing, you will have access to all the functions in the module.  When the functions are in a module, they're called methods.\n",
    "\n",
    "Let's create a module that contains our OLS regression methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ols_mod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ols_mod.py\n",
    "\n",
    "\"\"\"Methods for performing OLS regression.\n",
    "This module provides the following methods:\n",
    "param_coeffs: Computes the best fit parameters\n",
    "              using OLS regression.\n",
    "predict: Predicts outputs based on the best-fit \n",
    "         coefficients from the OLS regression.\n",
    "score: Computes how good of a fit the prediction is.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def param_coeffs(training_data, X):\n",
    "    \"\"\"Compute the best fit parameters.\n",
    "    INPUTS:\n",
    "        training_data: Data from the training set\n",
    "        X: Attributes\n",
    "    OUTPUT: \n",
    "        beta: Best fit parameters computed from \n",
    "              an OLS calculation.\n",
    "    \"\"\"\n",
    "    # Create a vector of ones and append \n",
    "    # to the last column of X.  Used to \n",
    "    # get the intercept intercepts.\n",
    "    column_of_ones = np.ones([X.shape[0], 1])\n",
    "    X = np.append(column_of_ones, X, axis=1)\n",
    "\n",
    "    # Now calculate the betas!\n",
    "    Xpinv = np.linalg.pinv(X) # Compute (X^T * X)^(-1) * X^T\n",
    "    beta = np.dot(Xpinv, training_data)\n",
    "    \n",
    "    # Finally, return the parameter coefficients\n",
    "    return beta\n",
    "\n",
    "def predict(X, beta):\n",
    "    \"\"\"Predict new outputs from linear fit\n",
    "    INPUTS:\n",
    "        X: Test data\n",
    "        beta:  Best fit parameters\n",
    "    OUTPUTS:\n",
    "        y_pred:  Predicted values\n",
    "    \"\"\"\n",
    "    y_pred = np.dot(X, beta[1:]) + beta[0]\n",
    "    return y_pred\n",
    "\n",
    "def score(test_data, prediction):\n",
    "    \"\"\"Calcuate coefficient of determination\n",
    "    INPUTS:\n",
    "        test_data: Test data from dataset\n",
    "        prediction:  Predicted values (from linear regression)\n",
    "    OUTPUTS:\n",
    "        R2: Coefficient of determination. Here, just the R^2 value.\n",
    "    \"\"\"\n",
    "    # Compute the R^2 value\n",
    "    y_bar = np.mean(test_data) # Calculate the mean of the test data\n",
    "    SST = np.sum((test_data - y_bar)**2.0) # Calculate the total sum of squares\n",
    "    SSR = np.sum((prediction - test_data)**2.0) # Calculate the sum of the square residuals\n",
    "    return 1.0 - SSR / SST # Return R^2 value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a module that provides methods for performing the OLS regression.  Let's use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing regression.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile regression.py\n",
    "import numpy as np\n",
    "from sklearn import datasets # import the datasets module\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ols_mod as ols # import our new module\n",
    "\n",
    "### Work with the Boston dataset\n",
    "dataset = datasets.load_boston() # load the Boston dataset on Boston house-prices\n",
    "# Split the dataset in the a training portion (used to get the parameters) and a \n",
    "# test portion (used to make predictions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], \n",
    "                                                    dataset['target'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "\n",
    "beta = ols.param_coeffs(y_train, X_train)\n",
    "y_pred = ols.predict(X_test, beta)\n",
    "R2 = ols.score(y_test, y_pred)\n",
    "print(\"R^2 for the Boston dataset is {0:4.3f}.\".format(R2))\n",
    "\n",
    "### Work with the breast_cancer dataset\n",
    "dataset = datasets.load_breast_cancer() # load the Boston dataset on Boston house-prices\n",
    "# Split the dataset in the a training portion (used to get the parameters) and a \n",
    "# test portion (used to make predictions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], \n",
    "                                                    dataset['target'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "beta = ols.param_coeffs(y_train, X_train)\n",
    "y_pred = ols.predict(X_test, beta)\n",
    "R2 = ols.score(y_test, y_pred)\n",
    "print(\"R^2 for the breast_cancer dataset is {0:4.3f}.\".format(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for the Boston dataset is 0.684.\n",
      "R^2 for the breast_cancer dataset is 0.732.\n"
     ]
    }
   ],
   "source": [
    "%run regression.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `regression.py` script is quite short now.  All of the methods are hidden from the user.  If you want to add a new method, you just add it to the `ols_reg` module.  The user can work with as many databases as they want and reuse the methods as long as they have access to the `ols_reg` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Concluding Remarks and Future Hopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've made it to the end, then you are really on the cusp of object-oriented programming (OOP).  You should have a better understanding of the following:\n",
    "* How to write readable scripts with just the right amount of comments.\n",
    "* The need to write functions to inject some modularity into your code bases.\n",
    "* The basics of encapsulation:\n",
    "  - How to hide implementation details from the user\n",
    "  - Why it's good to hide some details from the user\n",
    "* How to create a simple module\n",
    "* How to import and use modules\n",
    "\n",
    "I hope that you start to use some of these ideas in your own research projects when you have the need to write code.  Remember:  Even if you're not a software developer, you can, and should, still write code that is easy to maintain and distribute (for your own sanity and for the sanity of your peers).  The more you use and explore these ideas, the better you'll get at them.  Eventually, you'll never want to go back!\n",
    "\n",
    "The next thing you should explore "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
